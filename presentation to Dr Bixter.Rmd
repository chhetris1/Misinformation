---
title: "Who falls for Misinformation?"
author: "Sanjay Chhetri"
date: " `r Sys.Date()` "
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Data Source
I obtained the dataset from a repository publicly shared by the authors of a published article. [Link to the article](https://doi.org/10.1016/j.dib.2020.106031)
For this article, the authors used the dataset to run a Confirmatory Factor Analysis. The sample is entirely from Africa, by design. The dataset represents a total of 21 African countries.
I used the dataset to run a multiple regression to find out what factors predict the subscription of COVID-related misinformation.

``` {r dataset, echo = T, warning = F}
library(tidyverse, quietly = T)
raw_data <- read_csv("covid_africa_data_untouched.csv")
head(raw_data)
names(raw_data) 
renamed_data <- raw_data %>% 
  rename_with(.cols = 11:23, .fn = ~ paste0("q", 1:13)) %>%
  rename(familiarity = contains("Do you know anyone"))
names(renamed_data[,c(8,11:23)])
```

The dataset was in csv file. After reading it in R, I subset it to include only the variables needed for my analysis. Two variables pertaining to the source of covid information and religious orientation could be included in the model but I opted not to use them. FOr the former, the questionnaire gave multiple choices on COVID information source and most participants chose various options. For religion,  vast majority chose Christianity and Islam, with only a handful with 'don't want to tell'/'other'/'neutral'. It would basically be comparing one religion vs another. 


## Reshaping the dataset
Here I select only the variables that are of use for my analysis. 
```{r wrangling, echo =T}
df1 <- renamed_data %>% mutate(gender = factor(Gender), 
         age_group = factor(`Age class`), 
         education = factor(`Highest level of education`), 
         familiarity = factor(familiarity)) %>%
  select(gender, age_group, education,  familiarity, q1:q13)
```


## Data Wrangling
Here I recategorieze some variables to make them more readable. 
```{r rearranging variables, echo = TRUE}
table(df1$age_group) 
# collapsing age class varible to three categories
levels(df1$age_group) <- list("Youths" = c("Less than 18 years", "18 - 24 years", "25 - 29 years"), 
                        "Adults" = c("30 - 34 years", "35 - 39 years", "40 - 49 years"), 
                        "Elderly" = c("50 - 59 years", "60 - 69 years", "70 years and above"))
sum(is.na(df1$age_group)) #checking missing values

table(df1$education)
levels(df1$education) <- list("Post_grad" =  "Post Graduate level", 
                              "College" = "Tertiary education",
                              "No_college" = c("No formal education", "Primary/Basic education", "Secondary/high school/form 4/5 education"))

table(df1$education)
sum(is.na(renamed_data$`Highest level of education`)) #checking na in raw data
sum(is.na(df1$education)) #checking NA's after manipulation

```
Collapsing various age groups into three general groups made sense to see the age effect with better clarity. 
Collapsing various education levels into three groups (post graduate level, college educated, and no college) facilitated a better comparison.

## More Data Manipulation
Here, I first convert the likert scale texts into their numerical equivalents as suggested by the data source. 
Then I aggregate the misinformation related columns taking average.

``` {r more wrangling, echo = TRUE}
df1[df1 == "Strongly Disagree"] <- "0"
df1[df1 == "Disagree"] <- "0"
df1[df1 == "Neutral"] <- "1"
df1[df1=="Agree"] <- "4"
df1[df1=="Strongly Agree"] <- "4"
head(df1)
class(df1$q1)
df1[, 5:17] <- lapply(df1[, 5:17], as.numeric)
class(df1$q1)
head(df1)
df1$q <- rowMeans(subset(df1, select = q1:q13), na.rm = T)
head(df1)

df <- df1 %>% select(gender, age_group, education, familiarity, q )
head(df)
```
Here, q is the outcome variable and represents the extent to which one is misinformed about COVID (subscribes to COVID related misinformation)

##What's the distribution of misinformation score (q)?

```{r dv_check, echo= TRUE}
ggplot(df, aes(q))+geom_histogram(color = "red", fill="blue")
```
This is to glimpse the distribution of our DV. 

## Regression

``` {r regression, echo = TRUE}
fit <- lm(q~gender+age_group+education+familiarity, data = df)
summary(fit)
```
The regression model with 'q' as the outcome and gender, age_group, education, and familiarity as explanatory variables is significant, F(6, 556) = 4.235, p<0.001. The model explains 4.37% of the variance in the misinformation index (outcome, denoted by q), with adjusted R squared at 0.034. 
Education is the only variable that significantly predicts the misinformation index. With no significant difference between college and post-grad educated people. People with no college significantly differed in misinformation index. On average, people with no colleged measured 0.65 points higher in misinformation index compared to to the post graduated educated group. 

##Is there Any interaction effect?

```{r interaction, echo = TRUE}
#check a suspect interaction
model1 <- lm(q~gender+age_group+education+familiarity+familiarity:education, data = df)
summary(model1)
```
Looks like there is not any interaction effect. 


## Some visualizations

Let the plots speak!

```{r data viz, echo = TRUE}
require(gridExtra)
p1 <- df %>% ggplot(aes(x=education, y=q))+ 
 geom_boxplot()
p2 <- df %>% ggplot(aes(age_group, y=q))+geom_boxplot()
p3 <- ggplot(df, aes(gender, q,))+geom_boxplot()
p4 <- ggplot(df, aes(familiarity, q))+geom_boxplot()
grid.arrange(p1, p2, p3, p4, ncol =2)

```

##Figment of Imagination

If we had a continuous/descrete predictor such as age, visualization would be more fun.

```{r imagined_stuff, echo = TRUE}
df2 <- df
age_img <- sample(18:70, size = 563, replace = TRUE)
df2$age <- age_img
df2 <- df2 %>% relocate(age, .before = q)
head(df2)
df2 %>% ggplot(aes(x=age, y = q, color = gender))+
  geom_point()+geom_smooth(method = "lm")

```

With imagined ages, expecting to see any tangible relationship is futile. 

